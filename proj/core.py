# core.py â€” Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù‘Ù†Ø© Ù…Ø¹ ØªØ­Ø³ÙŠÙ†Ø§Øª Ù…ÙˆØ«ÙˆÙ‚ÙŠØ© Ùˆ readiness
# -*- coding: utf-8 -*-
import pandas as pd
import random
import os, sys, json, pickle, subprocess, re, logging
os.environ["OPENROUTER_KEY"] = "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"

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("core")

# ===== Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø³Ø§Ø±Ø§Øª Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ Ø£ÙŠ Ù†Ø¸Ø§Ù… =====
BASE_DIR = os.path.dirname(__file__)
PKL_PATH = os.getenv("PKL_PATH", os.path.join(BASE_DIR, "m1", "dept_models.pkl"))
logger.info(f"[DEBUG] Looking for dept_models.pkl at: {PKL_PATH} | Exists: {os.path.exists(PKL_PATH)}")

# ===== Config validation on startup =====
REQUIRED_ENV = ["OPENROUTER_KEY"]  # Ø£Ø¶Ù Ø£ÙŠ Ù…ØªØºÙŠØ±Ø§Øª env Ù…Ø·Ù„ÙˆØ¨Ø©
missing_env = [k for k in REQUIRED_ENV if not os.getenv(k)]
if missing_env:
    logger.warning(f"Missing required environment variables: {missing_env}")

if not os.path.exists(PKL_PATH):
    logger.warning(f"PKL file not found: {PKL_PATH}")

# ===== ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ØªÙ†Ø¨Ù‘Ø¦ M1 Ø¥Ù† ØªÙˆÙØ± =====
try:
    from m1.m1_predect_dept import M1DeptPredictor
    m1_dept = M1DeptPredictor(pkl_path=PKL_PATH, min_required=4)
    logger.info("[DEBUG] M1DeptPredictor loaded.")
except Exception as e:
    logger.error(f"M1DeptPredictor init failed: {e}", exc_info=True)
    m1_dept = None


PER_CLASS_IMPORTANCE_PATH = os.path.join(BASE_DIR, "per_class_feature_importance.xlsx")
TOP_MODEL_SHEET = "WeightedEnsemble"  # ÙŠÙ…ÙƒÙ†Ùƒ ØªØºÙŠÙŠØ±Ù‡ Ø­Ø³Ø¨ Ø§Ù„Ø­Ø§Ø¬Ø©

try:
    df_importance = pd.read_excel(PER_CLASS_IMPORTANCE_PATH, sheet_name=TOP_MODEL_SHEET)
    # Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ù…ÙˆØ³: class_name -> list of features Ù…Ø±ØªØ¨Ø© Ø­Ø³Ø¨ importance ØªÙ†Ø§Ø²Ù„ÙŠÙ‹Ø§
    importance_dict = {
        class_name: (
            df_class[df_class['importance'] > 0]
            .sort_values('importance', ascending=False)['feature']
            .tolist()
        )
        for class_name, df_class in df_importance.groupby('class_name')
    }
    print(f"[DEBUG] Loaded per-class feature importance for {len(importance_dict)} classes")
except Exception as e:
    print(f"[ERROR] Could not load per-class importance: {e}")
    importance_dict = {}



# ===== Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© =====
def parse_llm_json(out: str):
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ JSON Ù…Ù† Ø¥Ø®Ø±Ø§Ø¬ LLM Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø¢Ù…Ù†Ø©
    """
    try:
        return json.loads(out)
    except json.JSONDecodeError:
        matches = re.findall(r'\{.*?\}', out, re.S)
        for m in matches:
            try:
                return json.loads(m)
            except json.JSONDecodeError:
                continue
        raise ValueError(f"LLM output cannot be parsed as JSON: {out}")

def safe_run(func, *args, **kwargs):
    """
    ØªØ´ØºÙŠÙ„ Ø¯Ø§Ù„Ø© Ù…Ø¹ ØªØ³Ø¬ÙŠÙ„ Ø£ÙŠ Ø§Ø³ØªØ«Ù†Ø§Ø¡Ø§Øª
    """
    try:
        return func(*args, **kwargs)
    except Exception as e:
        logger.error(f"Exception in {func.__name__}: {e}", exc_info=True)
        raise

# ===== Health-check / readiness =====
def health_check():
    report = {
        "status": "ok",
        "errors": [],
        "checks": {}
    }
        # ØªØ­Ù‚Ù‚ Ø£Ù† M1 ÙŠØªØ£Ø«Ø± Ø¨Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
    dist_empty = run_M1_on_answers({})
    dist_real  = run_M1_on_answers({"fever": 1, "cough": 1})

    if dist_empty == dist_real:
        raise RuntimeError("M1 output not affected by inputs")


    # 1ï¸âƒ£ Ù…Ù„ÙØ§Øª ÙˆØ¨ÙŠØ¦Ø©
    if not os.path.exists(PKL_PATH):
        report["errors"].append("PKL file missing")
        report["checks"]["pkl"] = False
    else:
        report["checks"]["pkl"] = True

    if m1_dept is None:
        report["errors"].append("M1 predictor not initialized")
        report["checks"]["m1_loaded"] = False
    else:
        report["checks"]["m1_loaded"] = True

    # 2ï¸âƒ£ Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ø­Ø±Ø¬Ø©
    for fn in [
        "normalize_value_for_key",
        "canonicalize_to_m1_keys",
        "run_M1_on_answers",
        "m1_followups"
    ]:
        if fn not in globals():
            report["errors"].append(f"Missing function: {fn}")
            report["checks"][fn] = False
        else:
            report["checks"][fn] = True

    # 3ï¸âƒ£ feature pool
    try:
        pool = m1_feature_pool()
        if not pool or not isinstance(pool, list):
            raise ValueError("Empty or invalid feature pool")
        report["checks"]["feature_pool"] = len(pool)
    except Exception as e:
        report["errors"].append(f"Feature pool error: {e}")
        report["checks"]["feature_pool"] = False

    # 4ï¸âƒ£ ØªØ¯ÙÙ‘Ù‚ ÙˆØ§Ù‚Ø¹ÙŠ (simulate user)
    try:
        fake_raw = {
            "fever": "yes",
            "dry_cough": "no",
            "age": "45",
            "bpsys": "130"
        }

        normalized = {
            k: normalize_value_for_key(k, v)
            for k, v in fake_raw.items()
        }

        canonical = canonicalize_to_m1_keys(normalized, pool)

        if not canonical:
            raise RuntimeError("Canonicalization dropped all features")

        dist = run_M1_on_answers(canonical)

        if not isinstance(dist, dict):
            raise RuntimeError("M1 returned invalid output")

        report["checks"]["m1_flow"] = True
    except Exception as e:
        report["errors"].append(f"M1 flow failed: {e}")
        report["checks"]["m1_flow"] = False

    # 5ï¸âƒ£ ØªØ­Ù‚Ù‚ Ù…Ù† Ø³ÙƒØ±Ø¨ØªØ§Øª M2
    m2_status = {}
    for disease, meta in DISEASE_REGISTRY.items():
        path = meta.get("script_path")
        m2_status[disease] = os.path.exists(path)
        if not m2_status[disease]:
            report["errors"].append(f"M2 script missing for {disease}")

    report["checks"]["m2_scripts"] = m2_status

    # Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
    if report["errors"]:
        report["status"] = "error"

    return report
# ===== Ø®Ø±Ø§ÙŠØ· Ø§Ù„ØªØ±Ù…ÙŠØ² =====
BOOL_MAP = {
    # Ø¹Ø±Ø¨ÙŠ
    "Ù†Ø¹Ù…": 1, "Ø§ÙŠ Ù†Ø¹Ù…": 1, "Ø¢Ù‡": 1, "ØµØ­": 1,
    "Ù„Ø§": 0, "ÙƒÙ„Ø§": 0, "Ù…Ùˆ": 0, "Ù…Ø´": 0,
    # Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ
    "yes": 1, "y": 1, "true": 1, "1": 1,
    "no": 0, "n": 0, "false": 0, "0": 0,
}

GENDER_MAP = {
    # Ø¹Ø±Ø¨ÙŠ
    "Ø°ÙƒØ±": 1, "Ø±Ø¬Ù„": 1,
    "Ø£Ù†Ø«Ù‰": 0, "Ø§Ù…Ø±Ø£Ø©": 0,
    # Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ
    "male": 1, "m": 1,
    "female": 0, "f": 0,
}

SMOKE_MAP = BOOL_MAP

ACTIVE_MAP = {
    # Ø¹Ø±Ø¨ÙŠ
    "Ù„Ø§ ØªÙ…Ø§Ø±ÙŠÙ† Ù…Ù†ØªØ¸Ù…Ø©": 0,
    "ØªÙ…Ø§Ø±ÙŠÙ† Ø®ÙÙŠÙØ© (Ù…Ø«Ù„ Ø§Ù„Ù…Ø´ÙŠ Ø£Ø­ÙŠØ§Ù†Ù‹Ø§)": 1,
    # Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ
    "no regular exercise": 0,
    "light exercise (like walking occasionally)": 1,
}

LIFESTYLE_MAP = {
    "Ù…Ø¯ÙŠÙ†Ø©": 1, "Ø¨Ù„Ø¯Ø©": 2, "Ù‚Ø±ÙŠØ©": 3,
    "city": 1, "town": 2, "village": 3,
}

CHP_MAP = {
    "ÙŠØ­Ø¯Ø« Ù…Ø¹ Ø§Ù„Ù…Ø¬Ù‡ÙˆØ¯ ÙˆÙŠØ²ÙˆÙ„ Ù…Ø¹ Ø§Ù„Ø±Ø§Ø­Ø©": 1,
    "Ø£Ù„Ù… ØµØ¯Ø± ØºÙŠØ± Ù†Ù…Ø·ÙŠ: ØºÙŠØ± Ù…Ø¹ØªØ§Ø¯ Ø£Ùˆ Ù…Ø®ØªÙ„Ù Ø¹Ù† Ø§Ù„Ø£Ù„Ù… Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ": 2,
    "Ø£Ù„Ù… ØµØ¯Ø± ØºÙŠØ± Ù…Ø±ØªØ¨Ø· Ø¨Ø§Ù„Ù‚Ù„Ø¨": 3,
    "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø£Ù„Ù… ØµØ¯Ø±": 4,
    "happens with exertion and goes away with rest": 1,
    "atypical chest pain: unusual or different from normal chest pain": 2,
    "chest pain not related to the heart": 3,
    "no chest pain": 4,
}

ECGPATT_MAP = {

    "Ø§Ø±ØªÙØ§Ø¹ st (Ø§Ø­ØªÙ…Ø§Ù„ Ù†ÙˆØ¨Ø© Ù‚Ù„Ø¨ÙŠØ©)": 1,
    "Ø§Ù†Ø®ÙØ§Ø¶ st (Ø§Ø­ØªÙ…Ø§Ù„ ØªØ¯ÙÙ‚ Ø¯Ù… Ù…Ù†Ø®ÙØ¶)": 2,
    "Ø§Ù†Ø¹ÙƒØ§Ø³ t (Ø§Ø­ØªÙ…Ø§Ù„ Ø¥Ø¬Ù‡Ø§Ø¯ Ø§Ù„Ù‚Ù„Ø¨)": 3,
    "Ø·Ø¨ÙŠØ¹ÙŠ": 4,
    "st-elevation (possible heart attack)": 1,
    "st-depression (possible reduced blood flow)": 2,
    "t-inversion (possible heart strain)": 3,
    "normal": 4,
}


# ===== Ù…ÙØ§ØªÙŠØ­ ÙˆØ®Ø±Ø§ÙŠØ· Ø§Ù„Ø£Ø³Ø¦Ù„Ø© =====
AUTO_MAPPING = {
    "fever": "Do you have fever?",
    "cough": "Do you have cough?",
    "fatigue": "Do you feel fatigue?",
    "headache_general": "Do you have frequent headache?",
    "blood_pressure": "Enter Blood Pressure reading:",
    "blood_glucose_level": "Enter Blood Glucose Level (mg/dL):",
    "bmi": "Enter Body Mass Index (BMI):",
    "bpsys": "Enter Systolic Blood Pressure (Sys):",
    "bpdias": "Enter Diastolic Blood Pressure (Dias):",
    "years": "Enter number of years:",
    "chp": "Enter value for chp:",
    "sex": "Select sex:",
    "gender": "Select gender:",
    "lifestyle": "Enter lifestyle code (numeric):",
    "ecgpatt": "Enter ECG pattern code (numeric):",
}

AUTO_MAPPING_AR = {
    "sore throat": "Ø£Ù„Ù…/Ø§Ù„ØªÙ‡Ø§Ø¨ Ø­Ù„Ù‚",
    "running nose": "Ø±Ø´Ø­/Ø³ÙŠÙ„Ø§Ù† Ø£Ù†Ù",
    "diabetes": "Ø³ÙƒØ±ÙŠ",
    "hyper tension": "Ø§Ø±ØªÙØ§Ø¹ Ø¶ØºØ·",
    "htn": "Ø§Ø±ØªÙØ§Ø¹ Ø¶ØºØ·",
    "breathing problem": "Ø¶ÙŠÙ‚ Ù†ÙØ³",
    "headache general": "ØµØ¯Ø§Ø¹ ",
    "headache": "ØµØ¯Ø§Ø¹",
    "fatigue": "ØªØ¹Ø¨",
    "dry cough": "Ø³Ø¹Ø§Ù„ Ø¬Ø§Ù",
    "fever": "Ø­Ù…Ù‘Ù‰",
    "fatigue_general": "ØªØ¹Ø¨ Ø¹Ø§Ù…",
    "fever_general": "Ø­Ù…Ù‘Ù‰",
    "Cough": "Ø³Ø¹Ø§Ù„",
    "difficulty_breathing": "Ø¶ÙŠÙ‚ Ø§Ù„ØªÙ†ÙØ³",
    "scaly patches on the skin": "Ø¨Ù‚Ø¹ Ù‚Ø´Ø±ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ø¬Ù„Ø¯",
    "nausea_or_vomiting": "ØºØ«ÙŠØ§Ù† Ø£Ùˆ Ù‚ÙŠØ¡",
    "swelling": "ØªÙˆØ±Ù‘Ù…",
    "back_pain": "Ø£Ù„Ù… Ø§Ù„Ø¸Ù‡Ø±",
    "fractures": "ÙƒØ³ÙˆØ±",
    "jaundice": "ÙŠØ±Ù‚Ø§Ù†",
    "distinct facial features (small jaw)": "Ù…Ù„Ø§Ù…Ø­ ÙˆØ¬Ù‡ Ù…Ù…ÙŠØ²Ø© (ÙÙƒ ØµØºÙŠØ±)",
    "wheezing": "ØµÙÙŠØ± Ø§Ù„ØªÙ†ÙØ³",
    "numbness_or_weakness_general": "Ø®Ø¯Ø± Ø£Ùˆ Ø¶Ø¹Ù Ø¹Ø§Ù…",
    "swelling of the legs or ankles": "ØªÙˆØ±Ù‘Ù… Ø§Ù„Ø³Ø§Ù‚ÙŠÙ† Ø£Ùˆ Ø§Ù„ÙƒØ§Ø­Ù„ÙŠÙ†",
    "intellectual disability": "Ø¥Ø¹Ø§Ù‚Ø© Ø°Ù‡Ù†ÙŠØ©",
    "chest_pain": "Ø£Ù„Ù… Ø§Ù„ØµØ¯Ø±",
    "increased urination or urine changes": "Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªØ¨ÙˆÙ„ Ø£Ùˆ ØªØºÙŠÙ‘Ø±Ø§Øª ÙÙŠ Ø§Ù„Ø¨ÙˆÙ„",
    "headaches": "ØµØ¯Ø§Ø¹",
    "developmental delays": "ØªØ£Ø®Ø± ÙÙŠ Ø§Ù„Ù†Ù…Ùˆ",
    "rash_general": "Ø·ÙØ­ Ø¬Ù„Ø¯ÙŠ Ø¹Ø§Ù…",
    "high blood pressure": "Ø§Ø±ØªÙØ§Ø¹ Ø¶ØºØ· Ø§Ù„Ø¯Ù…",
    "decreased appetite": "Ø§Ù†Ø®ÙØ§Ø¶ Ø§Ù„Ø´Ù‡ÙŠØ©",
    "difficulty concentrating": "ØµØ¹ÙˆØ¨Ø© Ø§Ù„ØªØ±ÙƒÙŠØ²",
    "blood_in_urine_or_stool": "Ø¯Ù… ÙÙŠ Ø§Ù„Ø¨ÙˆÙ„ Ø£Ùˆ Ø§Ù„Ø¨Ø±Ø§Ø²",
    "slow healing of wounds": "Ø¨Ø·Ø¡ Ø§Ù„ØªØ¦Ø§Ù… Ø§Ù„Ø¬Ø±ÙˆØ­",
    "facial_numbness_or_weakness": "Ø®Ø¯Ø± Ø£Ùˆ Ø¶Ø¹Ù ÙÙŠ Ø§Ù„ÙˆØ¬Ù‡",
    "abnormal_urine": "Ø¨ÙˆÙ„ ØºÙŠØ± Ø·Ø¨ÙŠØ¹ÙŠ",
    "heart_rate_issues": "Ù…Ø´ÙƒÙ„Ø§Øª ÙÙŠ Ù…Ø¹Ø¯Ù„ Ø¶Ø±Ø¨Ø§Øª Ø§Ù„Ù‚Ù„Ø¨",
    "painful urination": "ØªØ¨ÙˆÙ„ Ù…Ø¤Ù„Ù…",
    "redness_general": "Ø§Ø­Ù…Ø±Ø§Ø± Ø¹Ø§Ù…",
    "abdominal_pain_general": "Ø£Ù„Ù… Ø¨Ø·Ù†ÙŠ Ø¹Ø§Ù…",
    "pelvic pain": "Ø£Ù„Ù… Ø§Ù„Ø­ÙˆØ¶",
    "frequent urination": "ØªÙƒØ±Ø§Ø± Ø§Ù„ØªØ¨ÙˆÙ„",
    "weight_loss_severe_or_unintentional": "ÙÙ‚Ø¯Ø§Ù† ÙˆØ²Ù† Ø´Ø¯ÙŠØ¯ Ø£Ùˆ ØºÙŠØ± Ù…Ù‚ØµÙˆØ¯",
    "weight_changes_general": "ØªØºÙŠÙ‘Ø±Ø§Øª ÙÙŠ Ø§Ù„ÙˆØ²Ù†",
    "loss of appetite": "ÙÙ‚Ø¯Ø§Ù† Ø§Ù„Ø´Ù‡ÙŠØ©",
    "jaw or arm pain": "Ø£Ù„Ù… Ø§Ù„ÙÙƒ Ø£Ùˆ Ø§Ù„Ø°Ø±Ø§Ø¹",
    "severe headache": "ØµØ¯Ø§Ø¹ Ø´Ø¯ÙŠØ¯",
    "heart_rate_irregularities": "Ø¹Ø¯Ù… Ø§Ù†ØªØ¸Ø§Ù… Ø¶Ø±Ø¨Ø§Øª Ø§Ù„Ù‚Ù„Ø¨",
    "sweating": "ØªØ¹Ø±Ù‘Ù‚",
    "dizziness": "Ø¯ÙˆØ®Ø©",
    "blind_spots": "Ø¨Ù‚Ø¹ Ø¹Ù…ÙŠØ§Ø¡ ÙÙŠ Ø§Ù„Ø±Ø¤ÙŠØ©",
    "joint_muscle_pain": "Ø£Ù„Ù… Ø§Ù„Ù…ÙØ§ØµÙ„ ÙˆØ§Ù„Ø¹Ø¶Ù„Ø§Øª",
    "sleep_or_appetite_changes": "ØªØºÙŠÙ‘Ø±Ø§Øª ÙÙŠ Ø§Ù„Ù†ÙˆÙ… Ø£Ùˆ Ø§Ù„Ø´Ù‡ÙŠØ©",
    "post-nasal drip": "Ø³ÙŠÙ„Ø§Ù† Ø®Ù„ÙÙŠ Ù„Ù„Ø£Ù†Ù",
    "Frequent Nosebleeds": "Ù†Ø²ÙŠÙ Ø£Ù†Ù Ù…ØªÙƒØ±Ø±",
    "thick nasal discharge": "Ø¥ÙØ±Ø§Ø²Ø§Øª Ø£Ù†ÙÙŠØ© ÙƒØ«ÙŠÙØ©",
    "bleeding tendencies": "Ù…ÙŠÙ„ Ù„Ù„Ù†Ø²ÙŠÙ",
    "bleeding_and_bruising": "Ù†Ø²ÙŠÙ ÙˆÙƒØ¯Ù…Ø§Øª",
    "stiffness": "ØªÙŠØ¨Ù‘Ø³"
}

BINARY_KEYS = [
]

DERIVED_TAGS = [
    "count_positive", "pct_positive",
    "respiratory_idx", "cardiac_idx", "neurology_idx", "ent_idx",
    "derm_idx", "gi_idx", "uro_idx", "heme_idx", "endocrine_idx", "immune_idx"
]

# ===== Ø¯ÙˆØ§Ù„ Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª =====
def core_start_conversation(payload):
    logger.debug(f"[core_start_conversation] Called with: {payload}")

    result = {
        "sid": "TEST-SID-001",
        "session": {
            "asked_symptoms": []   # ğŸ‘ˆ Ù…Ù‡Ù… Ø¬Ø¯Ù‹Ø§
        },
        "ask": [
            {
                "name": "initial",
                "type": "text",
                "q": "Ø§Ø°ÙƒØ± Ù„ÙŠ ÙƒÙ„ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„ØªÙŠ ØªØ´Ø¹Ø± Ø¨Ù‡Ø§."
            }
        ]
    }

    logger.debug(f"[core_start_conversation] Returning: {result}")
    return result

def core_handle_answers(payload):
    """
    ØªØ¯ÙÙ‘Ù‚ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø­Ø³Ù‘Ù†:
    - Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    - ØªØ­Ø¯ÙŠØ« asked_symptoms
    - Ø·Ø±Ø­ Ø£Ø³Ø¦Ù„Ø© M1 checkbox Ø¹Ù„Ù‰ Ø¯ÙØ¹Ø§Øª
    - Ø§Ù„ØªÙˆÙ‚Ù Ø¹Ù†Ø¯ Ù†ÙØ§Ø¯ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø£Ùˆ Ø§Ù„Ø§ÙƒØªÙØ§Ø¡
    - Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø­Ø³Ø¨ Ø£Ù‡Ù…ÙŠØªÙ‡Ø§ Ù„ÙƒÙ„ Ù‚Ø³Ù… Ø¨Ø´ÙƒÙ„ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ
    """

    logger.debug(f"[core_handle_answers] Payload: {payload}")

    sid = payload.get("sid", "NO-SID")
    session = payload.get("session", {})

    # Ø¬Ù…Ø¹ ÙƒÙ„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
    answers_accumulated = session.get("answers_accumulated", {})

    # Ø¯Ù…Ø¬ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù…Ù† checkbox
    if "answers" in payload:
        new_answers = payload["answers"]
        for k, v in new_answers.items():
            if k not in answers_accumulated:
                answers_accumulated[k] = []
            answers_accumulated[k].extend(v)

    # =========================
    # Ø¥Ø¯Ø§Ø±Ø© asked_symptoms
    # =========================
    asked = set(session.get("asked_symptoms", []))
    for vals in answers_accumulated.values():
        asked.update(vals)

    # =========================
    # ØªØ­Ø¯ÙŠØ« top_department Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠÙ‹Ø§ Ø­Ø³Ø¨ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©
    # =========================
    feature_pool = m1_feature_pool()
    flat_answers = flatten_checkbox_answers(answers_accumulated)
    flat_answers = canonicalize_to_m1_keys(flat_answers, feature_pool)  # âœ…
    
    # âœ… Ø­Ù‚Ù† 0 Ù„Ø£ÙŠ Ø¹Ø±Ø¶ Ø¹ÙØ±Ø¶ Ø¶Ù…Ù† asked ÙˆÙ„Ù… ÙŠØ¸Ù‡Ø± ÙƒÙ…ÙˆØ¬Ø¨ ÙÙŠ flat_answers
    asked_zero_raw = {a: 0 for a in asked or []}
    asked_zero_canon = canonicalize_to_m1_keys(asked_zero_raw, feature_pool)
    for k in (asked_zero_canon or {}):
        if k not in flat_answers:
            flat_answers[k] = 0

    m1_scores = run_M1_on_answers(flat_answers)
    session["M1_scores"] = m1_scores  # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬

    top_department = None
    if m1_scores:
        top_department = max(m1_scores, key=m1_scores.get)

    # =========================
    # ØªÙˆÙ„ÙŠØ¯ Ø£Ø³Ø¦Ù„Ø© M1 Ø­Ø³Ø¨ Ø§Ù„Ø£Ù‡Ù…ÙŠØ©
    # =========================
    feature_pool = m1_feature_pool()


    question, asked = generate_questions_from_columns(
        columns=feature_pool,
        asked_set=asked,
        batch_size=5,
        m1_scores=session.get("M1_scores"),
        answered_map=session.get("answers", {}),
        add_entire_batch_to_asked=False,
        lang=session.get("lang", "ar")  # âœ… ØªÙ…Ø±ÙŠØ± Ø§Ù„Ù„ØºØ© Ù…Ù† Ø§Ù„Ø¬Ù„Ø³Ø©
    )

    # =========================
    # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¬Ù„Ø³Ø©
    # =========================
    session["asked_symptoms"] = list(asked)
    session["answers_accumulated"] = answers_accumulated

    # =========================
    # Ø¥Ù† ÙˆÙØ¬Ø¯ Ø³Ø¤Ø§Ù„ Ø¬Ø¯ÙŠØ¯ â†’ Ø§Ø³Ø£Ù„Ù‡
    # =========================
    if question:
        logger.debug(f"[core_handle_answers] Asking next M1 checkbox batch | top_department={top_department}")
        return {
            "ask": [question],
            "sid": sid,
            "session": session
        }

    # =========================
    # Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø¹Ø±Ø§Ø¶ Ø¬Ø¯ÙŠØ¯Ø© Ø£Ùˆ Ø§Ù„Ø§ÙƒØªÙØ§Ø¡ â†’ ØªØ´ØºÙŠÙ„ M2
    # =========================
    logger.debug("[core_handle_answers] No more symptoms or sufficiency reached, final M1 scores")

    m2_result = None
    if top_department:
        disease = DEPT_TO_DISEASE.get(top_department)
        if disease:
            m2_input = flatten_checkbox_answers(answers_accumulated)
            m2_result = run_M2(disease, m2_input)
            logger.debug(f"[core_handle_answers] M2 result for {disease}: {m2_result}")

    return {
        "sid": sid,
        "result": {
            "M1": m1_scores,
            "M2": m2_result  # âœ… Ø§Ù„Ø¢Ù† M2 ØªÙØ±Ø¬Ø¹ Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ø¹ Ø§Ù„Ù†ØªÙŠØ¬Ø©
        },
        "session": session
    }

# ===== ØªØ­Ù…ÙŠÙ„ Ù…ÙØ§ØªÙŠØ­ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ù† PKL =====
def _load_m1_cols_from_pkl():
    try:
        with open(PKL_PATH, "rb") as f:
            PKL = pickle.load(f)
        effective = PKL.get("effective_feature_cols") or PKL.get("selected_features")
        feature_cols = PKL.get("feature_cols", [])
        base_cols = [c for c in feature_cols if c not in DERIVED_TAGS]
        final_cols = [c for c in (effective or base_cols) if c in base_cols] if effective else base_cols
        print(f"[DEBUG] M1 training features loaded: count={len(final_cols)}")
        return final_cols
    except Exception as e:
        print(f"[ERROR] Unable to read PKL features: {e}")
        return None

def m1_feature_pool():
    if m1_dept and hasattr(m1_dept, "original_feature_cols"):
        cols = list(m1_dept.original_feature_cols)
        if cols:
            print(f"[DEBUG] Predictor training-only features: {len(cols)}")
            return cols
        return _load_m1_cols_from_pkl() or []


# ===== ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© =====
def checkbox_question(col: str):
    label = AUTO_MAPPING.get(col, f"Do you have {col.replace('_',' ')}?")
    return {"name": col, "type": "checkbox", "q": label}

def radio_question(col: str, options):
    label = AUTO_MAPPING.get(col, f"Choose {col.replace('_',' ')}:")
    return {"name": col, "type": "radio", "options": options, "q": label}





def generate_questions_from_columns(
    columns,
    asked_set=None,
    batch_size=5,
    m1_scores=None,
    answered_map=None,
    add_entire_batch_to_asked=False,
    lang: str = "ar"  # âœ… Ø¬Ø¯ÙŠØ¯: Ù„ØºØ© Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ ("ar" Ø£Ùˆ "en")
):
    """
    ÙŠÙˆÙ„Ù‘Ø¯ Ø¯ÙØ¹Ø© Ø£Ø¹Ø±Ø§Ø¶ (checkbox) Ø­ØµØ±Ø§Ù‹ Ù…Ù† Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŒ
    Ù…Ø¹ Ù…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø± ØªÙ…Ø§Ù…Ù‹Ø§:
      - Ø£ÙŠ Ø¹Ø±Ø¶ Ø³ÙØ¦Ù„ Ø³Ø§Ø¨Ù‚Ù‹Ø§ Ù„Ø§ ÙŠÙØ¹Ø§Ø¯.
      - Ø£ÙŠ Ø¹Ø±Ø¶ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (0 Ø£Ùˆ 1) Ù„Ø§ ÙŠÙØ¹Ø§Ø¯.

    Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©:
      1) Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„Ù…Ù‡Ù…Ù‘Ø© ÙˆÙÙ‚ ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… (m1_scores Ø¥Ù† ÙˆÙØ¬Ø¯ØªØŒ ÙˆØ¥Ù„Ø§ importance_dict).
      2) Ø¨Ù‚ÙŠØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ØºÙŠØ± Ø§Ù„Ù…ÙØ¶Ø§ÙØ©.
    """

    # --- Ø­Ø±Ø§Ø³Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª ---
    # asked_set â†’ set
    if asked_set is None:
        asked_set = set()
    elif not isinstance(asked_set, set):
        try:
            asked_set = set(asked_set)
        except Exception:
            asked_set = set()

    columns      = columns or []
    answered_map = answered_map or {}

    # --- ØªØ·Ø¨ÙŠØ¹ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØ¨Ù†Ø§Ø¡ Ø®Ø±ÙŠØ·Ø© lower -> original ---
    def norm(s): return (s or "").strip().lower()

    pool_lc      = {norm(c) for c in columns}
    pool_lc_map  = {norm(c): c for c in columns}  # key: lower, val: original

    # asked (Ù…Ø·Ø¨Ù‘Ø¹)
    asked_lc = {norm(a) for a in asked_set}

    # answered_map: Ø§Ø­ØµØ±Ù‡ ÙÙŠ Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙÙ‚Ø·ØŒ Ø«Ù… Ø·Ø¨Ù‘Ø¹
    answered_lc = set()
    if answered_map:
        for k in answered_map.keys():
            kn = norm(k)
            if kn in pool_lc:
                answered_lc.add(kn)

    # Ø£ÙŠ Ø¹Ù†ØµØ± ÙÙŠ avoid_set Ù„Ù† ÙŠÙØ³Ø£Ù„ Ù…Ø¬Ø¯Ø¯Ù‹Ø§
    avoid_set = asked_lc | answered_lc

    remaining_lc = set()
    remaining    = []

    # --- ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… ---
    # ØªØ­ØµÙŠÙ† m1_scores: ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ importance_dict
    if m1_scores:
        sorted_departments = sorted(
            (k for k in m1_scores.keys() if k in importance_dict),
            key=lambda k: m1_scores[k],
            reverse=True
        )
    else:
        sorted_departments = list(importance_dict.keys()) if isinstance(importance_dict, dict) else []

    # (1) Ø¶Ù… Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„Ù…Ù‡Ù…Ø© Ø­Ø³Ø¨ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… (Ø¥Ù† ØªÙˆÙÙ‘Ø± importance_dict)
    if sorted_departments and isinstance(importance_dict, dict):
        for dept in sorted_departments:
            feats = importance_dict.get(dept, []) or []
            for f in feats:
                fl = norm(f)
                # Ø¶Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© + ØºÙŠØ± Ù…ÙƒØ±Ø±Ø© + ØºÙŠØ± Ù…Ø³Ø¤ÙˆÙ„Ø© Ø³Ø§Ø¨Ù‚Ù‹Ø§ + ØºÙŠØ± Ø¶Ù…Ù† avoid_set
                if fl in pool_lc and fl not in remaining_lc and fl not in avoid_set:
                    remaining.append(pool_lc_map[fl])  # Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø£ØµÙ„ÙŠ
                    remaining_lc.add(fl)

    # (2) Ø¨Ù‚ÙŠØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (fallback/Ø§Ø³ØªÙƒÙ…Ø§Ù„)
    for c in columns:
        cl = norm(c)
        if cl in pool_lc and cl not in remaining_lc and cl not in avoid_set:
            remaining.append(pool_lc_map[cl])
            remaining_lc.add(cl)

    # Ù„Ø§ Ø´ÙŠØ¡ Ù„Ù„Ø³Ø¤Ø§Ù„
    if not remaining:
        return None, asked_set

    # Ø¯ÙØ¹Ø© (Ø­Ø¬Ù… Ø«Ø§Ø¨Øª)
    batch = remaining[:batch_size]

    # Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ Ø§Ø²Ø¯ÙˆØ§Ø¬ÙŠØ© Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¯ÙØ¹Ø© (ÙˆÙÙ‚ lowercase) Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø£ØµÙ„ÙŠ
    uniq = {}
    for c in batch:
        key = norm(c)
        if key not in uniq:
            uniq[key] = c  # Ø§Ø­ØªÙØ¸ Ø¨Ø§Ù„Ø£ØµÙ„


    def _en_text(s: str) -> str:
        # ØªÙˆÙ„ÙŠØ¯ Ù†Øµ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ Ø¨Ø³ÙŠØ· Ù…Ù† Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯ (fallback)
        return (s or "").replace("_", " ").strip()

    options = []
    for c in uniq.values():
        label_ar = AUTO_MAPPING_AR.get(c, c)
        label_en = _en_text(c)
        options.append({
            "value": c,
            # Ù†Ø¶Ø¨Ø· label Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
            "label": label_en if lang == "en" else label_ar,
            # ÙˆÙ†Ø­ØªÙØ¸ Ø¨Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠØ© Ù„Ù„ÙˆØ§Ø¬Ù‡Ø©
            "label_ar": label_ar,
            "label_en": label_en
        })


    q_ar = "Ø§Ø®ØªØ± ÙƒÙ„ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„ØªÙŠ ØªØ´Ø¹Ø± Ø¨Ù‡Ø§ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø£Ø¯Ù†Ø§Ù‡:"
    q_en = "Select all the symptoms you are experiencing from the list below:"

    question = {
        "name": "symptoms_m1",
        "type": "checkbox",
        "options": options,
        # Ù†Ø¶Ø¨Ø· q Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        "q": q_en if lang == "en" else q_ar,
        # ÙˆÙ†Ø­ØªÙØ¸ Ø¨Ø§Ù„Ù†ØµÙŠÙ† Ù…Ø¹Ù‹Ø§ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø­Ø±Ù‘ÙŠØ©
        "q_ar": q_ar,
        "q_en": q_en
    }

    # Ø³ÙŠØ§Ø³Ø© Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ asked:
    # - Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ¹ØªØ¨Ø± Ø£Ù† ÙƒÙ„ Ø®ÙŠØ§Ø± Ø¸Ù‡Ø± Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù‚Ø¯ "Ø³ÙØ¦Ù„" (Ø­ØªÙ‰ Ù„Ùˆ Ù„Ù… ÙŠØ­Ø¯Ø¯Ù‡) ÙØ£Ø¨Ù‚ÙÙ‡Ø§ True.
    # - Ø¥Ù† Ø£Ø±Ø¯Øª Ø§Ø­ØªØ³Ø§Ø¨ "Ø³Ø¤Ø§Ù„" ÙÙ‚Ø· Ù„Ù…Ø§ Ø§Ø®ØªØ§Ø±Ù‡ Ø§Ù„Ù…Ø±ÙŠØ¶ØŒ Ø§Ø¬Ø¹Ù„Ù‡Ø§ False ÙˆØ£Ø¶Ù Ø§Ù„Ù…Ø®ØªØ§Ø± Ø¹Ù†Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©.
    if add_entire_batch_to_asked:
        asked_set.update(uniq.values())

    return question, asked_set




# ===== Ø£Ø³Ø¦Ù„Ø© M2 Ù…ÙƒØªÙˆØ¨Ø© ÙŠØ¯ÙˆÙŠÙ‹Ø§ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© =====
def m2_manual_questions_ar(disease: str):
    """
    Ø£Ø³Ø¦Ù„Ø© Ù…ÙƒØªÙˆØ¨Ø© Ø¯Ø§Ø®Ù„ Ø§Ù„ÙƒÙˆØ¯ Ù„ÙƒÙ„ Ù…Ø±Ø¶ M2 Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
    ÙƒÙ„ Ø³Ø¤Ø§Ù„ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³Ù…ØŒ Ø§Ù„Ù†ÙˆØ¹ (radio/checkbox/number)ØŒ Ø§Ù„Ù†ØµØŒ ÙˆØ§Ù„Ø®ÙŠØ§Ø±Ø§Øª Ø¥Ø°Ø§ Ù…ÙˆØ¬ÙˆØ¯Ø©
    """
    if disease == "HeartDisease":

        return [
            {"name": "age", "type": "number", "q": "Ø£Ø¯Ø®Ù„ Ø¹Ù…Ø±Ùƒ:"},
            {"name": "sex", "type": "radio", "q": "Ø§Ø®ØªØ± Ø§Ù„Ø¬Ù†Ø³:", "options": ["Ø°ÙƒØ±", "Ø£Ù†Ø«Ù‰"]},
            {"name": "smoke", "type": "radio", "q": "Ù‡Ù„ ØªØ¯Ø®Ù†ØŸ", "options": ["Ù„Ø§", "Ù†Ø¹Ù…"]},
            {"name": "years", "type": "number", "q": "ÙƒÙ… Ø¹Ø¯Ø¯ Ø³Ù†ÙˆØ§Øª Ø§Ù„ØªØ¯Ø®ÙŠÙ†ØŸ"},
            {"name": "chp", "type": "radio", "q": "Ø§Ø®ØªØ± Ù†ÙˆØ¹ Ø£Ù„Ù… Ø§Ù„ØµØ¯Ø±:", "options": [
                "ÙŠØ­Ø¯Ø« Ù…Ø¹ Ø§Ù„Ù…Ø¬Ù‡ÙˆØ¯ ÙˆÙŠØ²ÙˆÙ„ Ù…Ø¹ Ø§Ù„Ø±Ø§Ø­Ø©",
                "Ø£Ù„Ù… ØµØ¯Ø± ØºÙŠØ± Ù†Ù…Ø·ÙŠ: ØºÙŠØ± Ù…Ø¹ØªØ§Ø¯ Ø£Ùˆ Ù…Ø®ØªÙ„Ù Ø¹Ù† Ø§Ù„Ø£Ù„Ù… Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ",
                "Ø£Ù„Ù… ØµØ¯Ø± ØºÙŠØ± Ù…Ø±ØªØ¨Ø· Ø¨Ø§Ù„Ù‚Ù„Ø¨",
                "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø£Ù„Ù… ØµØ¯Ø±"
            ]},
            {"name": "height", "type": "number", "q": "Ø£Ø¯Ø®Ù„ Ø·ÙˆÙ„Ùƒ (Ø³Ù…):"},
            {"name": "weight", "type": "number", "q": "Ø£Ø¯Ø®Ù„ ÙˆØ²Ù†Ùƒ (ÙƒØ¬Ù…):"},
            {"name": "fh", "type": "radio", "q": "Ù‡Ù„ Ù„Ø¯ÙŠÙƒ ØªØ§Ø±ÙŠØ® Ø¹Ø§Ø¦Ù„ÙŠ Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù‚Ù„Ø¨ØŸ", "options": ["Ù„Ø§", "Ù†Ø¹Ù…"]},
            {"name": "active", "type": "radio", "q": "Ù‡Ù„ ØªÙ…Ø§Ø±Ø³ Ù†Ø´Ø§Ø·Ù‹Ø§ Ø¨Ø¯Ù†ÙŠÙ‹Ø§ØŸ", "options": [
                "Ù„Ø§ ØªÙ…Ø§Ø±ÙŠÙ† Ù…Ù†ØªØ¸Ù…Ø©",
                "ØªÙ…Ø§Ø±ÙŠÙ† Ø®ÙÙŠÙØ© (Ù…Ø«Ù„ Ø§Ù„Ù…Ø´ÙŠ Ø£Ø­ÙŠØ§Ù†Ù‹Ø§)"
            ]},
            {"name": "lifestyle", "type": "radio", "q": "Ø§Ø®ØªØ± Ù†Ù…Ø· Ø­ÙŠØ§ØªÙƒ:", "options": ["Ù…Ø¯ÙŠÙ†Ø©", "Ø¨Ù„Ø¯Ø©", "Ù‚Ø±ÙŠØ©"]},
            {"name": "ihd", "type": "radio", "q": "Ù‡Ù„ Ø£Ø¬Ø±ÙŠØª Ù‚Ø³Ø·Ø±Ø© Ù‚Ù„Ø¨ÙŠØ© Ø£Ùˆ Ø£ÙŠ ØªØ¯Ø®Ù„ ÙÙŠ Ø§Ù„Ù‚Ù„Ø¨ØŸ", "options": ["Ù„Ø§", "Ù†Ø¹Ù…"]},
            {"name": "hr", "type": "number", "q": "Ø£Ø¯Ø®Ù„ Ù…Ø¹Ø¯Ù„ Ø¶Ø±Ø¨Ø§Øª Ø§Ù„Ù‚Ù„Ø¨ (HR):"},
            {"name": "bpsys", "type": "number", "q": "Ø£Ø¯Ø®Ù„ Ø¶ØºØ· Ø§Ù„Ø¯Ù… Ø§Ù„Ø§Ù†Ù‚Ø¨Ø§Ø¶ÙŠ (Sys):"},
            {"name": "bpdias", "type": "number", "q": "Ø£Ø¯Ø®Ù„ Ø¶ØºØ· Ø§Ù„Ø¯Ù… Ø§Ù„Ø§Ù†Ø¨Ø³Ø§Ø·ÙŠ (Dias):"},
            {"name": "dm", "type": "radio", "q": "Ù‡Ù„ Ù„Ø¯ÙŠÙƒ Ù…Ø±Ø¶ Ø§Ù„Ø³ÙƒØ±ÙŠØŸ", "options": ["Ù„Ø§", "Ù†Ø¹Ù…"]},
            {"name": "htn", "type": "radio", "q": "Ù‡Ù„ Ù„Ø¯ÙŠÙƒ Ø§Ø±ØªÙØ§Ø¹ Ø¶ØºØ· Ø§Ù„Ø¯Ù…ØŸ", "options": ["Ù„Ø§", "Ù†Ø¹Ù…"]},
            {"name": "ecgpatt", "type": "radio", "q": "Ø§Ø®ØªØ± Ù†Ù…Ø· ØªØ®Ø·ÙŠØ· Ø§Ù„Ù‚Ù„Ø¨:", "options": [
                "Ø§Ø±ØªÙØ§Ø¹ ST (Ø§Ø­ØªÙ…Ø§Ù„ Ù†ÙˆØ¨Ø© Ù‚Ù„Ø¨ÙŠØ©)",
                "Ø§Ù†Ø®ÙØ§Ø¶ ST (Ø§Ø­ØªÙ…Ø§Ù„ ØªØ¯ÙÙ‚ Ø¯Ù… Ù…Ù†Ø®ÙØ¶)",
                "Ø§Ù†Ø¹ÙƒØ§Ø³ T (Ø§Ø­ØªÙ…Ø§Ù„ Ø¥Ø¬Ù‡Ø§Ø¯ Ø§Ù„Ù‚Ù„Ø¨)",
                "Ø·Ø¨ÙŠØ¹ÙŠ"
            ]},     
        ]
        
    
    elif disease == "Diabetes":

        return [
            {"name": "gender", "type": "radio", "q": "Ø§Ø®ØªØ± Ø§Ù„Ø¬Ù†Ø³:", "options": ["Ø°ÙƒØ±", "Ø£Ù†Ø«Ù‰"]},
            {"name": "age", "type": "number", "q": "Ø£Ø¯Ø®Ù„ Ø¹Ù…Ø±Ùƒ:"},
            {"name": "hypertension", "type": "radio", "q": "Ù‡Ù„ Ù„Ø¯ÙŠÙƒ Ø§Ø±ØªÙØ§Ø¹ Ø¶ØºØ· Ø§Ù„Ø¯Ù…ØŸ", "options": ["Ù„Ø§", "Ù†Ø¹Ù…"]},
            {"name": "heart_disease", "type": "radio", "q": "Ù‡Ù„ Ù„Ø¯ÙŠÙƒ Ù…Ø±Ø¶ ÙÙŠ Ø§Ù„Ù‚Ù„Ø¨ØŸ", "options": ["Ù„Ø§", "Ù†Ø¹Ù…"]},
            {"name": "bmi", "type": "number", "q": "Ø£Ø¯Ø®Ù„ Ù…Ø¤Ø´Ø± ÙƒØªÙ„Ø© Ø§Ù„Ø¬Ø³Ù… (BMI):"},
            {"name": "blood_glucose_level", "type": "number", "q": "Ø£Ø¯Ø®Ù„ Ù…Ø³ØªÙˆÙ‰ Ø³ÙƒØ± Ø§Ù„Ø¯Ù… (Ù…Ù„Øº/Ø¯ÙŠØ³ÙŠÙ„ØªØ±):"},
        ]
        
    return []


# ===== Ø£Ø³Ø¦Ù„Ø© M2 Ù…ÙƒØªÙˆØ¨Ø© ÙŠØ¯ÙˆÙŠÙ‹Ø§ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© =====
def m2_manual_questions(disease: str):
    """
    Ø£Ø³Ø¦Ù„Ø© Ù…ÙƒØªÙˆØ¨Ø© Ø¯Ø§Ø®Ù„ Ø§Ù„ÙƒÙˆØ¯ Ù„ÙƒÙ„ Ù…Ø±Ø¶ M2 Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
    ÙƒÙ„ Ø³Ø¤Ø§Ù„ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³Ù…ØŒ Ø§Ù„Ù†ÙˆØ¹ (radio/checkbox/number)ØŒ Ø§Ù„Ù†ØµØŒ ÙˆØ§Ù„Ø®ÙŠØ§Ø±Ø§Øª Ø¥Ø°Ø§ Ù…ÙˆØ¬ÙˆØ¯Ø©
    """
    if disease == "HeartDisease":
        return [
            {"name": "age", "type": "number", "q": "Enter your age:"},
            {"name": "sex", "type": "radio", "q": "Select your sex:", "options": ["Male", "Female"]},
            {"name": "smoke", "type": "radio", "q": "Do you smoke?", "options": ["No", "Yes"]},
            {"name": "years", "type": "number", "q": "How many years have you been smoking?"},
            {"name": "chp", "type": "radio", "q": "select your chest pain (chp):", "options": ["Happens with exertion and goes away with rest", "Atypical chest pain: unusual or different from normal chest pain", "Chest pain not related to the heart", "No chest pain"]},
            {"name": "height", "type": "number", "q": "Enter your height (cm):"},
            {"name": "weight", "type": "number", "q": "Enter your weight (kg):"},
            {"name": "fh", "type": "radio", "q": "Do you have a family history of heart disease?", "options": ["No", "Yes"]},
            {"name": "active", "type": "radio", "q": "Are you physically active?", "options": ["No regular exercise", "Light exercise (like walking occasionally)"]},
            {"name": "lifestyle", "type": "radio", "q": "select your lifestyle:", "options": ["City", "Town", "Village"]},
            {"name": "ihd", "type": "radio", "q": "Do you have any cardiac catheterization or any intervention into the heart?", "options": ["No", "Yes"]},
            {"name": "hr", "type": "number", "q": "Enter your Heart Rate (HR):"},
            {"name": "bpsys", "type": "number", "q": "Enter your Systolic Blood Pressure (Sys):"},
            {"name": "bpdias", "type": "number", "q": "Enter your Diastolic Blood Pressure (Dias):"},
            {"name": "dm", "type": "radio", "q": "Do you have Diabetes?", "options": ["No", "Yes"]},
            {"name": "htn", "type": "radio", "q": "Do you have Hypertension?", "options": ["No", "Yes"]},
            {"name": "ecgpatt", "type": "radio", "q": "select your lifestyle:", "options": ["ST-Elevation (Possible heart attack)", "ST-Depression (Possible reduced blood flow)", "T-Inversion (Possible heart strain)", "Normal"]},

        ]
    elif disease == "Diabetes":
        return [
            {"name": "gender", "type": "radio", "q": "Select your gender:", "options": ["Male", "Female"]},
            {"name": "age", "type": "number", "q": "Enter your age:"},
            {"name": "hypertension", "type": "radio", "q": "Do you have Hypertension?", "options": ["No", "Yes"]},
            {"name": "heart_disease", "type": "radio", "q": "Do you have Heart Disease?", "options": ["No", "Yes"]},
            {"name": "bmi", "type": "number", "q": "Enter Body Mass Index (BMI):"},
            {"name": "blood_glucose_level", "type": "number", "q": "Enter Blood Glucose Level (mg/dL):"},
        ]
    return []



def generate_questions(model_name, feature_pool=None, disease_required=None, lang="ar", limit=5):
    """
    ÙˆØ§Ø¬Ù‡Ø© ØªÙˆÙ„ÙŠØ¯ Ø£Ø³Ø¦Ù„Ø© Ø¹Ø§Ù…Ø©:
    - M1: ÙŠØ¹ÙŠØ¯ Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø£Ø³Ø¦Ù„Ø© checkbox (Ø³Ø¤Ø§Ù„ ÙˆØ§Ø­Ø¯ Ø¶Ù…Ù† Ù‚Ø§Ø¦Ù…Ø©) Ø­Ø³Ø¨ Ø§Ù„Ù„ØºØ©.
    - M2: ÙŠØ¹ÙŠØ¯ Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø±Ø¶ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø­Ø³Ø¨ Ø§Ù„Ù„ØºØ©.
    """
    # âœ… M1 â†’ Ù†Ø±Ø¬Ù‘Ø¹ Ù‚Ø§Ø¦Ù…Ø© Ø£Ø³Ø¦Ù„Ø© Ø¬Ø§Ù‡Ø²Ø©
    if model_name == "M1" and feature_pool:
        q, _asked = generate_questions_from_columns(
            columns=feature_pool,
            asked_set=set(),
            batch_size=limit,
            lang=lang  # âœ… ØªÙ…Ø±ÙŠØ± Ø§Ù„Ù„ØºØ©
        )
        # Ù„Ù Ø§Ù„Ø³Ø¤Ø§Ù„ ÙÙŠ Ù‚Ø§Ø¦Ù…Ø© ÙƒÙ…Ø§ ØªØªÙˆÙ‚Ø¹ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
        return [q] if q else []

    # âœ… M2 â†’ Ø¬Ù…Ø¹ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ÙŠØ¯ÙˆÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
    if model_name == "M2" and disease_required:
        questions = []
        for disease in disease_required:
            if lang == "ar":
                questions.extend(m2_manual_questions_ar(disease))
            else:
                questions.extend(m2_manual_questions(disease))
        return questions

    return []

    if model_name == "M2" and disease_required:
        questions = []
        for disease in disease_required:
            if lang == "ar":
                questions.extend(m2_manual_questions_ar(disease))
            else:
                questions.extend(m2_manual_questions(disease))
        return questions

    return []
# ===== ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù‚ÙŠÙ… =====
def normalize_value_for_key(key: str, v):
    """
    Normalize user input values for M1 / M2 models
    Supports Arabic & English categorical mappings
    """

    if v is None:
        return 0

    # =========================
    # Ø£Ø±Ù‚Ø§Ù… ØªÙ…Ø± Ù…Ø¨Ø§Ø´Ø±Ø©
    # =========================
    if isinstance(v, (int, float)):
        return v

    if not isinstance(v, str):
        return v

    s = v.strip().lower()

    # =========================
    # Ù†Ø¹Ù… / Ù„Ø§ (Ø¹Ø§Ù…)
    # =========================
    if s in BOOL_MAP:
        return BOOL_MAP[s]

    # =========================
    # ØªØ±Ù…ÙŠØ² Ø­Ø³Ø¨ Ø§Ù„Ù…ÙØªØ§Ø­ (M2)
    # =========================
    if key in {"sex", "gender"}:
        return GENDER_MAP.get(s, 0)

    if key in {"smoke", "dm", "htn", "ihd", "fh", "hypertension", "heart_disease"}:
        return BOOL_MAP.get(s, 0)

    if key == "active":
        return ACTIVE_MAP.get(s, 0)

    if key == "lifestyle":
        return LIFESTYLE_MAP.get(s, 0)

    if key == "chp":
        return CHP_MAP.get(s, 0)

    if key == "ecgpatt":
        return ECGPATT_MAP.get(s, 0)

    # =========================
    # Ø£Ø±Ù‚Ø§Ù… ÙƒÙ†Øµ
    # =========================
    try:
        return float(s)
    except ValueError:
        return v
# ===== Ø®Ø±Ø§Ø¦Ø· Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ ÙˆÙ…ÙØ§ØªÙŠØ­Ù‡Ø§ =====
DISEASE_REGISTRY = {
    "Diabetes": {
        "script_path": os.getenv("DIAB_SCRIPT", os.path.join(BASE_DIR, "m2", "diabetes_prediction", "predict.py")),
        "required_keys": ["gender", "age", "hypertension", "heart_disease", "bmi", "blood_glucose_level"]
    },
    "HeartDisease": {
        "script_path": os.getenv("HEART_SCRIPT", os.path.join(BASE_DIR, "m2", "heart_disease2", "predict.py")),
        "required_keys": [
            "age", "sex", "smoke", "years", "chp", "height", "weight", "fh", "active",
            "lifestyle", "ihd", "hr", "dm", "bpsys", "bpdias", "htn", "ecgpatt"
        ]
    }
}
DEPT_TO_DISEASE = {
    "Cardiology": "HeartDisease",
    "Oncology": "Diabetes",
    "ENT": "Diabetes",
    "Dermatology": "Diabetes",
    "Gastroenterology": "Diabetes",
    "Neurology": "Diabetes",
    "Urology/Nephrology": "Diabetes",
    "Hematology": "Diabetes",
    "Immunology": "Diabetes",
    "pediatrics": "Diabetes",
    "Gentics Disorders": "Diabetes",
    "Infectious Diseases": "Diabetes",
    "General Medicine": "Diabetes",
    "Internal Medicine": "Diabetes",
    "Orthopedics": "Diabetes",
    "Pediatrics": "Diabetes",
    "Psychiatry": "Diabetes",
    "Surgery": "Diabetes",
    "Therapy": "Diabetes",
    "Respiratory": "Diabetes",
    "Uncategorized": "Diabetes"

}
def get_required_keys_for_disease(disease: str):
    return DISEASE_REGISTRY.get(disease, {}).get("required_keys", [])

def flatten_checkbox_answers(answers_accumulated: dict):
    """
    ÙŠØ­ÙˆÙ‘Ù„:
    {"symptoms_m1": ["fever", "cough"]}
    Ø¥Ù„Ù‰:
    {"fever": 1, "cough": 1}
    """
    flat = {}

    for _, values in (answers_accumulated or {}).items():
        if isinstance(values, list):
            for v in values:
                flat[v] = 1

    return flat

# ===== ØªØ´ØºÙŠÙ„ M1 =====
def run_M1_on_answers(answers: dict):

    if m1_dept is None:
        logger.warning("run_M1_on_answers: M1 predictor not initialized.")
        return {}
    try:
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… safe_run Ù„Ø¶Ù…Ø§Ù† ØªØ³Ø¬ÙŠÙ„ Ø£ÙŠ Ø§Ø³ØªØ«Ù†Ø§Ø¡
        result = safe_run(m1_dept.predict_dict, answers or {}, top=5)
        return {k: float(v) for k, v in result.items() if isinstance(v, (int, float))}

    except Exception as e:
        logger.error(f"run_M1_on_answers failed: {e}")
        return {}

# ===== ØªØ´ØºÙŠÙ„ M2 =====
def run_M2(disease: str, data: dict):

    selected = DISEASE_REGISTRY.get(disease, {})
    data = dict(data or {})

    # ØµÙÙ‘Ø± Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ© ÙˆØ­ÙˆÙ‘Ù„ ÙƒÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ø¥Ù„Ù‰ Ø£Ø¹Ø¯Ø§Ø¯
    for k in selected.get("required_keys", []):
        v = data.get(k, 0)
        if v in (None, "", " ", "null"):
            v = 0
        v = normalize_value_for_key(k, v)
        if isinstance(v, str):
            try:
                v = float(v.strip())
            except Exception:
                v = 0
        data[k] = v

    # Ù…Ù„Ø¡ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
    for k in selected.get("required_keys", []):
        data.setdefault(k, 0)

    if os.getenv("DEBUG_M2_IO", "0") == "1":
        logger.info(f"[M2 INPUT::{disease}] {json.dumps(data, ensure_ascii=False)}")

    try:
        script_path = selected.get("script_path")
        if not script_path or not os.path.exists(script_path):
            logger.error(f"M2 script not found for {disease}")
            return None

        proc = subprocess.run(
            [sys.executable, script_path],
            input=json.dumps(data).encode("utf-8"),
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            check=False
        )
        stdout = (proc.stdout or b"").decode("utf-8", errors="replace").strip()
        stderr = (proc.stderr or b"").decode("utf-8", errors="replace").strip()

        if proc.returncode != 0:
            logger.error(f"M2 script returned non-zero exit code {proc.returncode}")
            logger.error(f"[STDERR]\n{stderr}")
            logger.error(f"[STDOUT]\n{stdout}")
            return None

        if not stdout:
            logger.error(f"M2 script returned empty stdout for '{disease}'")
            logger.error(f"[STDERR]\n{stderr}")
            return None

        # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­ÙˆÙŠÙ„ stdout Ø¥Ù„Ù‰ Ø±Ù‚Ù…
        try:
            score = float(stdout.strip())
        except ValueError:
            # fallback: Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙŠ Ø±Ù‚Ù… ÙÙŠ stdout
            matches = re.findall(r"[\-\+]?\d*\.?\d+", stdout)
            if matches:
                score = float(matches[0])
                logger.warning(f"Parsed numeric value from non-strict output: {matches[0]}")
            else:
                logger.error(f"Unable to parse numeric score from M2 stdout: '{stdout}'")
                logger.error(f"[STDERR]\n{stderr}")
                return None

        return max(0.0, min(1.0, score))
    except Exception as e:
        logger.error(f"Exception while running M2 for '{disease}': {e}", exc_info=True)
        return None



def m1_is_sufficient(
    answers: dict,
    max_questions: int = 25,   # Ø­Ø¯Ù‘Ùƒ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶
    min_positive: int = 3,      # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ§Øª
    min_questions: int = 10,    # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ÙØ¬Ø§Ø¨ Ø¹Ù†Ù‡Ø§ ÙØ¹Ù„ÙŠÙ‹Ø§
    margin_delta: float = 0.05    # Ù‡Ø§Ù…Ø´ Ø§Ù„ÙØ§Ø±Ù‚ Ø¨ÙŠÙ† Ø£Ø¹Ù„Ù‰ ÙˆØ«Ø§Ù†ÙŠ Ù‚Ø³Ù…
):
    """
    Ù…Ù†Ø·Ù‚ Ø¥ÙŠÙ‚Ø§Ù M1:
    - ÙŠØ­Ø³Ø¨ Ø§Ù„Ø§ÙƒØªÙØ§Ø¡ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„ØªÙŠ ØªÙ…Øª Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù†Ù‡Ø§ ÙØ¹Ù„ÙŠÙ‹Ø§ (0 Ø£Ùˆ >0).
    - 0 ØªÙØ­Ø³Ø¨ ÙƒØ³Ø¤Ø§Ù„ Ù…ÙØ¬Ø§Ø¨ Ù„ÙƒÙ†Ù‡Ø§ Ù„ÙŠØ³Øª Ø¥Ø´Ø§Ø±Ø© Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©.
    - ÙŠØ¹ØªÙ…Ø¯ Ø§Ù„Ù‚Ø±Ø§Ø± Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ§ØªØŒ ÙˆØ¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©ØŒ ÙˆÙ‡Ø§Ù…Ø´ Ø§Ù„ØªÙˆØ²ÙŠØ¹.
    """

    if not isinstance(answers, dict):
        return False, "invalid answers"

    # Ù†Ø¹ØªØ¨Ø± Â«Ù…ÙØ´Ø§Ù‡ÙØ¯Ø§Ù‹Â» ÙƒÙ„ Ù…ÙØªØ§Ø­ Ù„Ù‡ Ù‚ÙŠÙ…Ø© Ù„ÙŠØ³Øª None (Ø³ÙˆØ§Ø¡ 0 Ø£Ùˆ >0)
    observed_items = {k: v for k, v in answers.items() if v is not None}

    # Ø§Ø­Ø³Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ÙØ¬Ø§Ø¨ Ø¹Ù†Ù‡Ø§ ÙØ¹Ù„ÙŠÙ‹Ø§
    total_questions = len(observed_items)

    # Ø§Ø­Ø³Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ§Øª (Ù‚ÙŠÙ… > 0 ÙÙ‚Ø·)
    def _to_num(v):
        s = str(v).strip().lower()
        if s in ("Ù†Ø¹Ù…", "yes", "true", "1"):
            return 1.0
        if s in ("Ù„Ø§", "no", "false", "0"):
            return 0.0
        try:
            return float(s)
        except Exception:
            # Ù‚ÙŠÙ… Ù†ØµÙŠØ© ØºÙŠØ± Ø±Ù‚Ù…ÙŠØ© ØªÙØ¹ØªØ¨Ø± ØºÙŠØ± Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©
            return 0.0

    positive_count = sum(1 for v in observed_items.values() if _to_num(v) > 0.0)

    # Ø´Ø±ÙˆØ· Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰
    if positive_count < min_positive:
        return False, "not enough positive signals"
    if total_questions < min_questions:
        return False, "not enough questions"

    # ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙØ´Ø§Ù‡ÙØ¯ ÙÙ‚Ø· (Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ø¥Ù† Ø£Ø±Ø¯Øª Ø§Ù„Ù‡Ø§Ù…Ø´)
    dist = run_M1_on_answers(observed_items) or {}
    scores = sorted(
        [v for v in dist.values() if isinstance(v, (int, float))],
        reverse=True
    )
    if len(scores) < 2:
        return False, "insufficient score distribution"

    top1, top2 = scores[0], scores[1]

    # Ù‚Ø±Ø§Ø± Ø§Ù„Ù‡Ø§Ù…Ø´
    if (top1 - top2) >= margin_delta:
        return True, "clear top-vs-second margin"

    # Ø­Ø¯ Ø£Ù‚ØµÙ‰ Ù„Ù„Ø£Ø³Ø¦Ù„Ø© (ÙŠÙØ­Ø³Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ÙØ¹Ù„ÙŠØ©ØŒ ÙˆÙ„ÙŠØ³ Ø·ÙˆÙ„ Ø§Ù„Ù€ pool)
    if total_questions >= max_questions:
        return True, "max questions reached"

    return False, "need more information"

##############
def canonicalize_to_m1_keys(extracted: dict, m1_keys: list):
    key_map = {k.lower(): k for k in (m1_keys or [])}

    out = {}
    for k, v in (extracted or {}).items():
        kl = k.lower()
        if kl in key_map:
            out[key_map[kl]] = v
    return out

# ===== Ø£Ø³Ø¦Ù„Ø© Ù…ØªØ§Ø¨Ø¹Ø§Øª M1 Ø¨Ø¯ÙˆÙ† ØªØ­ÙŠÙ‘Ø² Ù…Ø¹ Ù†Øµ Ø¹Ø±Ø¨ÙŠ ÙƒØ§Ù…Ù„ =====
import random




def m1_followups(answers, top_dept=None, limit=5, lang="ar", m1_scores=None):
    """
    Wrapper ÙÙ‚Ø·:
    ÙŠØ¹ÙŠØ¯ Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø´ÙŠÙƒ Ø¨ÙˆÙƒØ³ Ù…Ù† Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„ÙˆØ­ÙŠØ¯ generate_questions_from_columns
    Ù…Ø¹ ØªÙ…Ø±ÙŠØ± Ø§Ù„Ù„ØºØ© Ùˆ(Ø§Ø®ØªÙŠØ§Ø±ÙŠÙ‹Ø§) Ø¯Ø±Ø¬Ø§Øª M1 Ù„ØªØ­Ø³ÙŠÙ† ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶.
    """
    asked = set((answers or {}).keys())
    pool = m1_feature_pool() or []

    q_list, _ = generate_questions_from_columns(
        columns=pool,
        asked_set=asked,
        batch_size=limit,
        m1_scores=m1_scores,      # âœ… Ù„Ùˆ Ù…ÙˆØ¬ÙˆØ¯Ø© Ø£ÙØ¶Ù„ ØªÙ…Ø±ÙŠØ±Ù‡Ø§
        lang=lang                  # âœ… ØªÙ…Ø±ÙŠØ± Ø§Ù„Ù„ØºØ©
    )
    # Ù†Ø¹ÙŠØ¯ Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ù‚Ø§Ø¦Ù…Ø© (list) Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø§Øª Ø§Ù„Ø¹Ù„ÙŠØ§
    return q_list if isinstance(q_list, list) else ([q_list] if q_list else [])


# ===== Guards =====
REQUIRED_FUNCS = ["m1_followups", "run_M1_on_answers", "run_M2"]
for fn in REQUIRED_FUNCS:
    if fn not in globals():
        raise RuntimeError(f"Missing required function: {fn}")

